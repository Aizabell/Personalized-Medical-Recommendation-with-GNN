{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1MF9BZzcC5awYnXMAs4Q_3OhNXD9xOynz","timestamp":1744825932531}],"machine_shape":"hm","gpuType":"T4","mount_file_id":"11OnuzGiNFNyHJesTGqSC3VMHBBP-irWG","authorship_tag":"ABX9TyNKQ/EN6DDX1ESD6z8WnI8M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import json\n","import joblib\n","import pandas as pd\n","import dask.dataframe as dd\n","\n","ckpt_path = \"/content/drive/MyDrive/AIT/ML/Project/personalized_medical_recommendation/baseline_models\"\n","data_path = \"/content/drive/MyDrive/AIT/ML/Project/personalized_medical_recommendation/preprocessing/processed/\"\n","\n","patients = pd.read_csv(os.path.join(data_path, \"processed_patients.csv\"))\n","diagnoses = pd.read_csv(os.path.join(data_path, \"processed_diagnoses.csv\"))\n","prescriptions = pd.read_csv(os.path.join(data_path, \"processed_prescriptions.csv\"))\n","procedures = pd.read_csv(os.path.join(data_path, \"processed_procedures.csv\"))\n","labevents = pd.read_csv(os.path.join(data_path, \"processed_labevents.csv\"))\n","admissions = pd.read_csv(os.path.join(data_path, \"processed_admissions.csv\"))"],"metadata":{"id":"5AaLRgPiYkIu","executionInfo":{"status":"ok","timestamp":1744871872199,"user_tz":-420,"elapsed":125017,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["patients.drop(columns=[\"Unnamed: 0\"], inplace=True)"],"metadata":{"id":"LuLF9hgwgwBO","executionInfo":{"status":"ok","timestamp":1744871872202,"user_tz":-420,"elapsed":93,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["diagnoses.disease_category[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Ot14McBYP_4r","executionInfo":{"status":"ok","timestamp":1744871872253,"user_tz":-420,"elapsed":51,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}},"outputId":"64f0c025-d9f2-4979-e07c-0f8bcd4a58b9"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hypertension with complications and secondary hypertension'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6bGPcA4SWQb","executionInfo":{"status":"ok","timestamp":1744871891201,"user_tz":-420,"elapsed":18948,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}},"outputId":"80e4e4b9-c188-4c20-8288-87066ba6f5e3"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:distributed.http.proxy:To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n","INFO:distributed.scheduler:State start\n","INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:46165\n","INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n","INFO:distributed.scheduler:Registering Worker plugin shuffle\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:39551'\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:41345'\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:40491'\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:43491'\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:40951 name: 3\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:40951\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52274\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:37403 name: 0\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37403\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52270\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:46699 name: 2\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:46699\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52282\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:37081 name: 1\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37081\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52288\n","INFO:distributed.scheduler:Receive client connection: Client-7d247974-1b56-11f0-8a8a-0242ac1c000c\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:52300\n","WARNING:distributed.shuffle._scheduler_plugin:Shuffle 45b85011a03b30c68c7fb0b8af2db9d3 initialized by task ('shuffle-transfer-45b85011a03b30c68c7fb0b8af2db9d3', 6) executed on worker tcp://127.0.0.1:37403\n","WARNING:distributed.shuffle._scheduler_plugin:Shuffle 45b85011a03b30c68c7fb0b8af2db9d3 deactivated due to stimulus 'task-finished-1744871879.4704738'\n","WARNING:distributed.shuffle._scheduler_plugin:Shuffle afec5c2c52544d9682570d1ccfa24e42 initialized by task ('shuffle-transfer-afec5c2c52544d9682570d1ccfa24e42', 7) executed on worker tcp://127.0.0.1:37081\n","WARNING:distributed.shuffle._scheduler_plugin:Shuffle afec5c2c52544d9682570d1ccfa24e42 deactivated due to stimulus 'task-finished-1744871879.6623204'\n","/usr/local/lib/python3.11/dist-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 14.92 MiB.\n","This may cause some slowdown.\n","Consider loading the data with Dask directly\n"," or using futures or delayed objects to embed the data into the graph without repetition.\n","See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 570.67 MiB.\n","This may cause some slowdown.\n","Consider loading the data with Dask directly\n"," or using futures or delayed objects to embed the data into the graph without repetition.\n","See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/dask/dataframe/multi.py:521: UserWarning: Merging dataframes with merge column data type mismatches: \n","+------------------------+------------+-------------+\n","| Merge columns          | left dtype | right dtype |\n","+------------------------+------------+-------------+\n","| ('hadm_id', 'hadm_id') | int64      | float64     |\n","+------------------------+------------+-------------+\n","Cast dtypes explicitly to avoid unexpected results.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 208.52 MiB.\n","This may cause some slowdown.\n","Consider loading the data with Dask directly\n"," or using futures or delayed objects to embed the data into the graph without repetition.\n","See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n","  warnings.warn(\n","WARNING:distributed.shuffle._scheduler_plugin:Shuffle c8622453daad83fcd4b45a88ba1ca3fa initialized by task ('hash-join-transfer-c8622453daad83fcd4b45a88ba1ca3fa', 2) executed on worker tcp://127.0.0.1:37081\n","WARNING:distributed.shuffle._scheduler_plugin:Shuffle 2b05458c8b8187a66b39c17dca7595d9 initialized by task ('hash-join-transfer-2b05458c8b8187a66b39c17dca7595d9', 0) executed on worker tcp://127.0.0.1:46699\n","WARNING:distributed.shuffle._scheduler_plugin:Shuffle c8622453daad83fcd4b45a88ba1ca3fa deactivated due to stimulus 'task-finished-1744871889.0176542'\n","WARNING:distributed.shuffle._scheduler_plugin:Shuffle 2b05458c8b8187a66b39c17dca7595d9 deactivated due to stimulus 'task-finished-1744871889.0176542'\n","INFO:distributed.scheduler:Remove client Client-7d247974-1b56-11f0-8a8a-0242ac1c000c\n","INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:52300; closing.\n","INFO:distributed.scheduler:Remove client Client-7d247974-1b56-11f0-8a8a-0242ac1c000c\n","INFO:distributed.scheduler:Close client connection: Client-7d247974-1b56-11f0-8a8a-0242ac1c000c\n","INFO:distributed.scheduler:Retire worker addresses (stimulus_id='retire-workers-1744871890.678114') (0, 1, 2, 3)\n","INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:39551'. Reason: nanny-close\n","INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n","INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:41345'. Reason: nanny-close\n","INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n","INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:40491'. Reason: nanny-close\n","INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n","INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:43491'. Reason: nanny-close\n","INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n","INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:52270; closing.\n","INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:52288; closing.\n","INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:52282; closing.\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:37403 name: 0 (stimulus_id='handle-worker-cleanup-1744871890.6898181')\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:37081 name: 1 (stimulus_id='handle-worker-cleanup-1744871890.6911094')\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:46699 name: 2 (stimulus_id='handle-worker-cleanup-1744871890.6923318')\n","INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:52274; closing.\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:40951 name: 3 (stimulus_id='handle-worker-cleanup-1744871890.6972213')\n","INFO:distributed.scheduler:Lost all workers\n","INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:41345' closed.\n","INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:43491' closed.\n","INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:39551' closed.\n","INFO:distributed.nanny:Nanny at 'tcp://127.0.0.1:40491' closed.\n","INFO:distributed.scheduler:Closing scheduler. Reason: unknown\n","INFO:distributed.scheduler:Scheduler closing all comms\n"]}],"source":["import json\n","import dask.dataframe as dd\n","from dask.distributed import Client\n","\n","# Initialize Dask client\n","client = Client(n_workers=4)  # Adjust based on CPU cores\n","\n","# Convert to Dask DataFrames\n","admissions_dd = dd.from_pandas(admissions, npartitions=4)\n","patients_dd = dd.from_pandas(patients, npartitions=4)\n","diagnoses_dd = dd.from_pandas(diagnoses, npartitions=8)\n","procedures_dd = dd.from_pandas(procedures, npartitions=8)\n","labevents_dd = dd.from_pandas(labevents, npartitions=8)\n","\n","# Convert to known categoricals (FIX for the error)\n","diagnoses_dd['disease_category_encoded'] = diagnoses_dd['disease_category_encoded'].astype('category').cat.as_known()\n","procedures_dd['procedure_category_encoded'] = procedures_dd['procedure_category_encoded'].astype('category').cat.as_known()\n","\n","# Disease categories features\n","diag_features = (\n","    dd.get_dummies(\n","        diagnoses_dd[['subject_id', 'hadm_id', 'disease_category_encoded']],\n","        columns=['disease_category_encoded']\n","    )\n","    .groupby(['subject_id', 'hadm_id'])\n","    .sum()\n","    .reset_index()\n",")\n","\n","# Procedure features\n","proc_features = (\n","    dd.get_dummies(\n","        procedures_dd[['subject_id', 'hadm_id', 'procedure_category_encoded']],\n","        columns=['procedure_category_encoded']\n","    )\n","    .groupby(['subject_id', 'hadm_id'])\n","    .sum()\n","    .reset_index()\n",")\n","\n","# Lab average features\n","lab_features = (\n","    labevents_dd.groupby([\"subject_id\", \"hadm_id\"])[\"valuenum_normalized\"]\n","    .mean()\n","    .reset_index()\n","    .rename(columns={\"valuenum_normalized\": \"avg_lab_value\"})\n",")\n","\n","# Merge all features\n","df = (\n","    admissions_dd.merge(patients_dd, on=\"subject_id\", how=\"left\")\n","    .merge(diag_features.compute(), on=[\"subject_id\", \"hadm_id\"], how=\"left\")  # Compute before merge\n","    .merge(proc_features.compute(), on=[\"subject_id\", \"hadm_id\"], how=\"left\")  # Compute before merge\n","    .merge(lab_features.compute(), on=[\"subject_id\", \"hadm_id\"], how=\"left\")   # Compute before merge\n",")\n","\n","# Handle categorical data\n","df[\"gender\"] = df[\"gender\"]\n","df[\"ethnicity\"] = df[\"ethnicity\"]\n","df[\"admission_type\"] = df[\"admission_type\"].map_partitions(lambda s: s.astype(\"category\").cat.codes, meta=('admission_type', 'int8'))\n","\n","# Fill NA values and compute final result\n","df = df.fillna(0).compute()\n","\n","# Clean up\n","client.close()"]},{"cell_type":"code","source":["from sklearn.preprocessing import MultiLabelBinarizer\n","\n","# Group all prescribed drugs per admission\n","target_series = prescriptions.groupby(['subject_id', 'hadm_id'])['drug'].apply(list).reset_index()\n","\n","# Merge with your Dask-processed DataFrame\n","df = df.merge(target_series, on=['subject_id', 'hadm_id'], how='left')\n","\n","# Fill any NaNs in drug column with empty lists\n","df['drug'] = df['drug'].apply(lambda x: x if isinstance(x, list) else [])\n","\n","# Fit MultiLabelBinarizer to **all drug names**\n","mlb = MultiLabelBinarizer()\n","y = mlb.fit_transform(df['drug'])"],"metadata":{"id":"yrHZuqsrhTZy","executionInfo":{"status":"ok","timestamp":1744871894429,"user_tz":-420,"elapsed":3228,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Save binarizer\n","joblib.dump(mlb, os.path.join(ckpt_path, \"mlb_encoder.pkl\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mgKFpAxMxMNe","executionInfo":{"status":"ok","timestamp":1744871894643,"user_tz":-420,"elapsed":205,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}},"outputId":"e0c28c61-111c-49a1-a09e-42585fe09566"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/AIT/ML/Project/personalized_medical_recommendation/baseline_models/mlb_encoder.pkl']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["X = df.drop(columns=[\n","    'subject_id', 'hadm_id', 'admittime', 'dischtime', 'drug'  # or embedding columns if doing regression\n","], errors='ignore')"],"metadata":{"id":"Fo8YuCMehycb","executionInfo":{"status":"ok","timestamp":1744871894706,"user_tz":-420,"elapsed":59,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jYYhuJRraEiV","executionInfo":{"status":"ok","timestamp":1744871894708,"user_tz":-420,"elapsed":1,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Multi-layered Perceptron"],"metadata":{"id":"p-BJzK0MRyOe"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","\n","# ------------------------ 1. Train/Val/Test Split ------------------------\n","\n","# First split: Train (70%) vs Temp (30%)\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Second split: Validation (15%) vs Test (15%)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","# ------------------------ 2. Convert to Torch Tensors ------------------------\n","\n","X_train_tensor = torch.tensor(X_train.values if hasattr(X_train, 'values') else X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","\n","X_val_tensor = torch.tensor(X_val.values if hasattr(X_val, 'values') else X_val, dtype=torch.float32)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n","\n","X_test_tensor = torch.tensor(X_test.values if hasattr(X_test, 'values') else X_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n","\n","# ------------------------ 3. Wrap in TensorDataset ------------------------\n","\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","val_dataset   = TensorDataset(X_val_tensor, y_val_tensor)\n","test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","# ------------------------ 4. Create DataLoaders ------------------------\n","\n","batch_size = 64\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","print(\"DataLoaders ready.\")\n","print(\"Train:\", len(train_loader))\n","print(\"Val  :\", len(val_loader))\n","print(\"Test :\", len(test_loader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0J7fAuT-SNHs","executionInfo":{"status":"ok","timestamp":1744871901130,"user_tz":-420,"elapsed":6420,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}},"outputId":"51ad230b-ebdb-49dd-8401-75b6d8ccb371"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["DataLoaders ready.\n","Train: 646\n","Val  : 139\n","Test : 139\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class DeepMultiLabelNet(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(DeepMultiLabelNet, self).__init__()\n","\n","        self.net = nn.Sequential(\n","            nn.Linear(input_dim, 1024),\n","            nn.BatchNorm1d(1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.4),\n","\n","            nn.Linear(1024, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Dropout(0.4),\n","\n","            nn.Linear(512, 256),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","\n","            nn.Linear(256, 128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","\n","            nn.Linear(128, output_dim),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"m8VDnv-QSjr7","executionInfo":{"status":"ok","timestamp":1744871901190,"user_tz":-420,"elapsed":57,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["input_dim = X_train_tensor.shape[1]\n","output_dim = y_train_tensor.shape[1]\n","\n","model = DeepMultiLabelNet(input_dim=input_dim, output_dim=output_dim)\n","\n","# Move to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load best model (example: best F1)\n","model.load_state_dict(torch.load(os.path.join(ckpt_path, \"best_f1_model.pth\")))\n","model.to(device)"],"metadata":{"id":"xp3OHTt1SxZD","executionInfo":{"status":"ok","timestamp":1744871903348,"user_tz":-420,"elapsed":2156,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"24c4011b-509d-4bfd-a108-15e5576c371a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeepMultiLabelNet(\n","  (net): Sequential(\n","    (0): Linear(in_features=472, out_features=1024, bias=True)\n","    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.4, inplace=False)\n","    (4): Linear(in_features=1024, out_features=512, bias=True)\n","    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU()\n","    (7): Dropout(p=0.4, inplace=False)\n","    (8): Linear(in_features=512, out_features=256, bias=True)\n","    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU()\n","    (11): Dropout(p=0.3, inplace=False)\n","    (12): Linear(in_features=256, out_features=128, bias=True)\n","    (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (14): ReLU()\n","    (15): Dropout(p=0.2, inplace=False)\n","    (16): Linear(in_features=128, out_features=4525, bias=True)\n","    (17): Sigmoid()\n","  )\n",")"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"B_W7bdF3yAcW"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","epochs = 1000\n","\n","# Track best metrics\n","best_acc = 0.0\n","best_f1 = 0.0\n","best_auc = 0.0\n","\n","for epoch in range(epochs):\n","    # ---------- Training ----------\n","    model.train()\n","    train_loss = 0.0\n","\n","    for batch_X, batch_y in train_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","\n","        optimizer.zero_grad()\n","        preds = model(batch_X)\n","        loss = criterion(preds, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    # ---------- Validation ----------\n","    model.eval()\n","    val_loss = 0.0\n","    all_preds = []\n","    all_targets = []\n","\n","    with torch.no_grad():\n","        for val_X, val_y in val_loader:\n","            val_X, val_y = val_X.to(device), val_y.to(device)\n","\n","            preds = model(val_X)\n","            loss = criterion(preds, val_y)\n","            val_loss += loss.item()\n","\n","            all_preds.append(preds.cpu().numpy())\n","            all_targets.append(val_y.cpu().numpy())\n","\n","    # Stack and threshold\n","    y_pred = np.vstack(all_preds)\n","    y_true = np.vstack(all_targets)\n","    y_pred_bin = (y_pred >= 0.5).astype(int)\n","\n","    # Metrics\n","    acc = accuracy_score(y_true, y_pred_bin)\n","    f1 = f1_score(y_true, y_pred_bin, average='micro')\n","    try:\n","        auc = roc_auc_score(y_true, y_pred, average='micro')\n","    except ValueError:\n","        auc = 0.0  # handle case when only one class present\n","\n","    # Logging\n","    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n","    print(f\"ðŸ”¹ Train Loss: {train_loss:.4f} | ðŸ”¸ Val Loss: {val_loss:.4f}\")\n","    print(f\"ðŸ“Š Accuracy : {acc:.4f} | F1 Micro: {f1:.4f} | ROC-AUC: {auc:.4f}\")\n","\n","    # ---------- Save Best Checkpoints ----------\n","    if acc > best_acc:\n","        best_acc = acc\n","        torch.save(model.state_dict(), os.path.join(ckpt_path, \"best_acc_model.pth\"))\n","        print(f\"âœ… Saved best Accuracy model\")\n","\n","    if f1 > best_f1:\n","        best_f1 = f1\n","        torch.save(model.state_dict(), os.path.join(ckpt_path, \"best_f1_model.pth\"))\n","        print(f\"âœ… Saved best F1 model\")\n","\n","    if auc > best_auc:\n","        best_auc = auc\n","        torch.save(model.state_dict(), os.path.join(ckpt_path, \"best_auc_model.pth\"))\n","        print(f\"âœ… Saved best AUC model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"kKvNYsWRRm8x","outputId":"a127c6c6-4b4a-4352-aa76-da09da277890","executionInfo":{"status":"error","timestamp":1744877371757,"user_tz":-420,"elapsed":6,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":11,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-a63c719dbd51>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \"\"\"\n\u001b[0;32m-> 1324\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1325\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \"\"\"\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1518\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1828\u001b[0m     \"\"\"\n\u001b[1;32m   1829\u001b[0m     \u001b[0m_check_zero_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1597\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m# for NumPy the usefulness is questionable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0;34mf\"CSC arrays don't support {arg1.ndim}D input. Use 2D\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 )\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mcoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coo_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coo_to_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     88\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mindex_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_index_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 self.coords = tuple(idx.astype(index_dtype, copy=False)\n\u001b[1;32m     92\u001b[0m                                      for idx in coords)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### Evaluate"],"metadata":{"id":"bTbqqOSByCoA"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n","\n","def evaluate_model(model, data_loader, criterion, device):\n","    model.eval()\n","    all_preds = []\n","    all_targets = []\n","    total_loss = 0.0\n","\n","    with torch.no_grad():\n","        for X_batch, y_batch in data_loader:\n","            X_batch = X_batch.to(device)\n","            y_batch = y_batch.to(device)\n","\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","            total_loss += loss.item()\n","\n","            all_preds.append(outputs.cpu().numpy())\n","            all_targets.append(y_batch.cpu().numpy())\n","\n","    # Stack and threshold\n","    y_pred = np.vstack(all_preds)\n","    y_true = np.vstack(all_targets)\n","    y_pred_bin = (y_pred >= 0.5).astype(int)\n","\n","    # Compute metrics\n","    acc = accuracy_score(y_true, y_pred_bin)\n","    f1 = f1_score(y_true, y_pred_bin, average='micro')\n","\n","    try:\n","        auc = roc_auc_score(y_true, y_pred, average='micro')\n","    except ValueError:\n","        auc = 0.0  # Not computable if labels are all 0 or 1 for a class\n","\n","    return {\n","        \"loss\": total_loss,\n","        \"accuracy\": acc,\n","        \"f1_micro\": f1,\n","        \"roc_auc_micro\": auc\n","    }"],"metadata":{"id":"mOhis4GlR2sN","executionInfo":{"status":"ok","timestamp":1744877376482,"user_tz":-420,"elapsed":44,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Load best model (example: best F1)\n","model.load_state_dict(torch.load(os.path.join(ckpt_path, \"best_f1_model.pth\")))\n","model.to(device)\n","\n","# Evaluate\n","results = evaluate_model(model, test_loader, criterion, device)\n","\n","# Print results\n","print(\"\\nðŸ§ª Final Test Set Evaluation:\")\n","print(f\"Loss       : {results['loss']:.4f}\")\n","print(f\"Accuracy   : {results['accuracy']:.4f}\")\n","print(f\"F1 Micro   : {results['f1_micro']:.4f}\")\n","print(f\"ROC-AUC    : {results['roc_auc_micro']:.4f}\")"],"metadata":{"id":"YtZKgTomURzY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744877392606,"user_tz":-420,"elapsed":13788,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}},"outputId":"631795b8-e4f8-4d4a-be70-a5ab2749429f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ§ª Final Test Set Evaluation:\n","Loss       : 2.1272\n","Accuracy   : 0.0807\n","F1 Micro   : 0.5245\n","ROC-AUC    : 0.9887\n"]}]},{"cell_type":"markdown","source":["## Inference"],"metadata":{"id":"IkNTaQzvLOvC"}},{"cell_type":"code","source":["import json\n","import joblib\n","import numpy as np\n","\n","mappings_path = \"/content/drive/MyDrive/AIT/ML/Project/personalized_medical_recommendation/baseline_models/mappings\"\n","\n","# Load mapping files\n","with open(os.path.join(mappings_path, \"admission_type_mapping.json\")) as f:\n","    admission_type_map = json.load(f)\n","\n","with open(os.path.join(mappings_path, \"ethnicity_mapping.json\")) as f:\n","    ethnicity_map = json.load(f)\n","\n","with open(os.path.join(mappings_path, \"disease_category_mapping.json\")) as f:\n","    disease_map = json.load(f)\n","\n","with open(os.path.join(mappings_path, \"procedure_category_mapping.json\")) as f:\n","    procedure_map = json.load(f)\n","\n","# Load scaler for lab values\n","scaler = joblib.load(os.path.join(mappings_path, \"scaler_valuenum_labevents.pkl\"))"],"metadata":{"id":"4X2zAerZLMwP","executionInfo":{"status":"ok","timestamp":1744877424005,"user_tz":-420,"elapsed":1746,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# This should be saved from training (or pulled from training df)\n","all_columns = joblib.load(os.path.join(mappings_path, \"feature_columns.pkl\"))  # You must have saved this during training\n","input_vector = np.zeros(len(all_columns))\n","column_index = {col: idx for idx, col in enumerate(all_columns)}"],"metadata":{"id":"qX-L1NfAYBG6","executionInfo":{"status":"ok","timestamp":1744877477743,"user_tz":-420,"elapsed":31,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Empty input\n","input_vector = np.zeros(len(column_index))\n","\n","# Raw input sample\n","sample = {\n","    \"age\": 0.0,\n","    \"length_of_stay\": 19.0,\n","    \"gender\": 1,  # Assuming 1 = M, 0 = F\n","    \"ethnicity\": \"WHITE\",\n","    \"admission_type\": \"EMERGENCY\",\n","    \"diseases\": [\"Liveborn\", \"Other perinatal conditions\"],\n","    \"procedures\": [\"Prophylactic vaccinations and inoculations\", \"Respiratory intubation and mechanical ventilation\"],\n","    \"lab_values\": [7.39, 22.0, 0.93]\n","}"],"metadata":{"id":"B0G0wD4pWTvN","executionInfo":{"status":"ok","timestamp":1744877574071,"user_tz":-420,"elapsed":3,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Basic fields\n","input_vector[column_index[\"age\"]] = sample[\"age\"]\n","input_vector[column_index[\"length_of_stay\"]] = sample[\"length_of_stay\"]\n","input_vector[column_index[\"gender\"]] = sample[\"gender\"]\n","input_vector[column_index[\"ethnicity\"]] = ethnicity_map[sample[\"ethnicity\"]]\n","input_vector[column_index[\"admission_type\"]] = admission_type_map[sample[\"admission_type\"]]\n","\n","# Lab values\n","lab_avg = np.mean(sample[\"lab_values\"])\n","lab_scaled = scaler.transform([[lab_avg]])[0][0]\n","input_vector[column_index[\"avg_lab_value\"]] = lab_scaled\n","\n","# Diseases (multi-hot)\n","for disease in sample[\"diseases\"]:\n","    if disease in disease_map:\n","        enc_id = disease_map[disease]\n","        col_name = f\"disease_category_encoded_{enc_id}\"\n","        if col_name in column_index:\n","            input_vector[column_index[col_name]] += 1\n","\n","# Procedures (multi-hot)\n","for proc in sample[\"procedures\"]:\n","    if proc in procedure_map:\n","        enc_id = procedure_map[proc]\n","        col_name = f\"procedure_category_encoded_{enc_id}\"\n","        if col_name in column_index:\n","            input_vector[column_index[col_name]] += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3MS1ShiYOSP","executionInfo":{"status":"ok","timestamp":1744877577463,"user_tz":-420,"elapsed":122,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}},"outputId":"ed3a031c-ca72-4150-9258-68ce04d04e73"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import torch\n","\n","model.eval()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","X_input = torch.tensor(input_vector, dtype=torch.float32).unsqueeze(0).to(device)\n","\n","with torch.no_grad():\n","    pred = model(X_input)  # Already passed through sigmoid if using BCELoss\n","\n","probs = pred.cpu().numpy()[0]"],"metadata":{"id":"911LLjrdYTML","executionInfo":{"status":"ok","timestamp":1744877581052,"user_tz":-420,"elapsed":58,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["top_k = 5\n","top_indices = probs.argsort()[-top_k:][::-1]\n","\n","# If you used MultiLabelBinarizer\n","mlb = joblib.load(os.path.join(ckpt_path, \"mlb_encoder.pkl\"))  # saved during training\n","predicted_labels = mlb.classes_[top_indices]\n","\n","print(\"Top predicted labels (drugs):\", predicted_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3q_ExVWYvk0","executionInfo":{"status":"ok","timestamp":1744877584368,"user_tz":-420,"elapsed":31,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}},"outputId":"662d039c-8671-4816-b795-e875ddc92dec"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Top predicted labels (drugs): ['NEO*PO*Ferrous Sulfate Elixer' 'Potassium Chloride' 'Sodium Chloride'\n"," 'NEO*IV*Gentamicin' 'Syringe (Neonatal) *D5W*']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YP82vOWGcklG","executionInfo":{"status":"aborted","timestamp":1744877371767,"user_tz":-420,"elapsed":5624636,"user":{"displayName":"Lu Kyaw","userId":"00606119636179503189"}}},"execution_count":null,"outputs":[]}]}