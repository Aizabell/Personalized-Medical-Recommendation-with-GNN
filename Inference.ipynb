{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5129,
     "status": "ok",
     "timestamp": 1743597994222,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "FtR3XKGtBCqA",
    "outputId": "aa329887-dd30-4132-c5fd-1e0e5a39909d"
   },
   "outputs": [],
   "source": [
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 13238,
     "status": "ok",
     "timestamp": 1743598007461,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "ppye0oNkBQOQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harryphoebus/miniconda3/envs/ML/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8932,
     "status": "ok",
     "timestamp": 1743598016398,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "K5ZqPVkbBcWP"
   },
   "outputs": [],
   "source": [
    "data = torch.load(\"./models/processed_graph.pt\", weights_only=False)\n",
    "\n",
    "ckpt_path = \"./checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1743598016596,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "SavDm0oRDZWg"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#metal\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1743598016647,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "mn6M0_NQByUw"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "class HeteroSAGELinkPredictor(nn.Module):\n",
    "    def __init__(self, metadata, output_dims, hidden_channels=64, out_channels=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # Message passing layers\n",
    "        self.conv1 = HeteroConv({\n",
    "            edge_type: SAGEConv((-1, -1), hidden_channels)\n",
    "            for edge_type in metadata[1]\n",
    "        }, aggr='sum')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            edge_type: SAGEConv((hidden_channels, hidden_channels), out_channels)\n",
    "            for edge_type in metadata[1]\n",
    "        }, aggr='sum')\n",
    "\n",
    "        # NEW: MLP that maps raw patient features â†’ same space as GNN\n",
    "        self.patient_encoder = nn.Sequential(\n",
    "            nn.Linear(44, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, out_channels)\n",
    "        )\n",
    "\n",
    "        # Decoder: combines patient, medication, and optional context features\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(out_channels * 5, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {k: F.relu(v) for k, v in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "    def encode_patient(self, patient_features):\n",
    "        return self.patient_encoder(patient_features)\n",
    "\n",
    "    def decode(\n",
    "        self,\n",
    "        z_patient,\n",
    "        z_medication,\n",
    "        z_disease,\n",
    "        z_procedure,\n",
    "        z_lab,\n",
    "        edge_index,\n",
    "        disease_ids=None,\n",
    "        procedure_ids=None,\n",
    "        lab_ids=None,\n",
    "    ):\n",
    "        src, dst = edge_index\n",
    "\n",
    "        # Default to zero vectors if ids are None (i.e., for inference without all context)\n",
    "        def get_context_embeddings(z, ids):\n",
    "            if ids is None:\n",
    "                return torch.zeros_like(z_patient[src])\n",
    "            return z[ids]\n",
    "\n",
    "        disease_emb = get_context_embeddings(z_disease, disease_ids)\n",
    "        proc_emb    = get_context_embeddings(z_procedure, procedure_ids)\n",
    "        lab_emb     = get_context_embeddings(z_lab, lab_ids)\n",
    "\n",
    "        # Concatenate all embeddings\n",
    "        combined = torch.cat([\n",
    "            z_patient[src],\n",
    "            z_medication[dst],\n",
    "            disease_emb,\n",
    "            proc_emb,\n",
    "            lab_emb\n",
    "        ], dim=1)\n",
    "\n",
    "        return self.decoder(combined).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 21416,
     "status": "ok",
     "timestamp": 1743598038066,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "ynJtdp3MDUa4"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Invalid buffer size: 33.34 GB",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     temp_conv1 \u001b[38;5;241m=\u001b[39m HeteroConv({\n\u001b[1;32m      7\u001b[0m         edge_type: SAGEConv((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m edge_type \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39medge_types\n\u001b[1;32m      9\u001b[0m     }, aggr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m     temp_output \u001b[38;5;241m=\u001b[39m \u001b[43mtemp_conv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     output_dims \u001b[38;5;241m=\u001b[39m {node_type: feat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m node_type, feat \u001b[38;5;129;01min\u001b[39;00m temp_output\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/torch_geometric/nn/conv/hetero_conv.py:158\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[0;34m(self, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[1;32m    161\u001b[0m     out_dict[dst] \u001b[38;5;241m=\u001b[39m [out]\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/var/folders/65/3ys5n1cd0h31fjm443lmzy5m0000gn/T/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_hplhv233.py:173\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m    167\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    168\u001b[0m         out,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m/var/folders/65/3ys5n1cd0h31fjm443lmzy5m0000gn/T/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_hplhv233.py:83\u001b[0m, in \u001b[0;36mcollect\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, \u001b[38;5;241m0\u001b[39m, _x_0)\n\u001b[0;32m---> 83\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:267\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:290\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m that are larger \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:271\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[0;34m(self, src, index)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Invalid buffer size: 33.34 GB"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    temp_conv1 = HeteroConv({\n",
    "        edge_type: SAGEConv((-1, -1), out_channels=64)\n",
    "        for edge_type in data.edge_types\n",
    "    }, aggr='sum').to(device)\n",
    "\n",
    "    temp_output = temp_conv1(data.x_dict, data.edge_index_dict)\n",
    "    output_dims = {node_type: feat.shape[1] for node_type, feat in temp_output.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1033,
     "status": "ok",
     "timestamp": 1743598039102,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "NqKMzGhkCob_",
    "outputId": "71c3d323-31dc-4071-ebae-ad7840aa213a"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model again with correct metadata and output dims\n",
    "model = HeteroSAGELinkPredictor(data.metadata(), output_dims=output_dims).to(device)\n",
    "\n",
    "# Load the best model weights\n",
    "model.load_state_dict(torch.load(os.path.join(ckpt_path, \"best_model_acc.pt\")))\n",
    "model.eval()  # Set to eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1743598039148,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "iJtGw7AGCY6f"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "def build_first_association_map(src_nodes, dst_nodes):\n",
    "    \"\"\"Build a mapping from patient to first associated node (disease/procedure/lab).\"\"\"\n",
    "    assoc_map = {}\n",
    "    for src, dst in zip(src_nodes.tolist(), dst_nodes.tolist()):\n",
    "        if src not in assoc_map:\n",
    "            assoc_map[src] = dst\n",
    "    return assoc_map\n",
    "\n",
    "def get_first_associated_node(assoc_map, patient_ids, default_val=-1):\n",
    "    \"\"\"Return first associated node for each patient in patient_ids.\"\"\"\n",
    "    return torch.tensor(\n",
    "        [assoc_map.get(pid.item(), default_val) for pid in patient_ids],\n",
    "        dtype=torch.long\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2600,
     "status": "ok",
     "timestamp": 1743598041758,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "mhjx4NRQCj_z"
   },
   "outputs": [],
   "source": [
    "# Build once before training\n",
    "edge_pd = data[\"patient\", \"has_disease\", \"disease\"].edge_index\n",
    "edge_pp = data[\"patient\", \"underwent\", \"procedure\"].edge_index\n",
    "edge_pl = data[\"patient\", \"has_lab\", \"lab\"].edge_index\n",
    "\n",
    "disease_map = build_first_association_map(edge_pd[0], edge_pd[1])\n",
    "procedure_map = build_first_association_map(edge_pp[0], edge_pp[1])\n",
    "lab_map = build_first_association_map(edge_pl[0], edge_pl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21062,
     "status": "ok",
     "timestamp": 1743598062815,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "9rpuDV0hE-d_"
   },
   "outputs": [],
   "source": [
    "# Step 1: Get node embeddings\n",
    "with torch.no_grad():\n",
    "    z_dict = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1743598612684,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "4zez0oUNCd8L"
   },
   "outputs": [],
   "source": [
    "# Example: predict score for patient node 42 and medication nodes 0-9\n",
    "patient_id = 1200\n",
    "num_meds = z_dict[\"medication\"].shape[0]\n",
    "med_ids = torch.arange(num_meds).to(device)\n",
    "\n",
    "# Step 2: Replace patient embeddings using the patient_encoder MLP\n",
    "patient_features = data[\"patient\"].x.to(device)\n",
    "z_dict[\"patient\"] = model.encode_patient(patient_features)  # <-- Encoder used here\n",
    "\n",
    "# Repeat patient_id N times (same length as med_ids)\n",
    "patients = torch.tensor([patient_id] * len(med_ids), device=device)\n",
    "\n",
    "edge_index = torch.stack([\n",
    "    torch.full_like(med_ids, fill_value=patient_id),  # source: patient\n",
    "    med_ids                                           # destination: meds\n",
    "], dim=0)\n",
    "\n",
    "disease_ids   = get_first_associated_node(disease_map, patients)\n",
    "procedure_ids = get_first_associated_node(procedure_map, patients)\n",
    "lab_ids       = get_first_associated_node(lab_map, patients)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    scores = model.decode(\n",
    "        z_patient     = z_dict[\"patient\"],\n",
    "        z_medication  = z_dict[\"medication\"],\n",
    "        z_disease     = z_dict[\"disease\"],\n",
    "        z_procedure   = z_dict[\"procedure\"],\n",
    "        z_lab         = z_dict[\"lab\"],\n",
    "        edge_index    = edge_index,\n",
    "        disease_ids   = disease_ids,\n",
    "        procedure_ids = procedure_ids,\n",
    "        lab_ids       = lab_ids\n",
    "    )\n",
    "    probs = torch.sigmoid(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1743598612843,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "wMvCFTiCFHjt",
    "outputId": "5eb46eb1-c088-4513-d23a-0b5411c99723"
   },
   "outputs": [],
   "source": [
    "topk = 15\n",
    "top_indices = probs.topk(topk).indices\n",
    "recommended_meds = med_ids[top_indices].cpu().numpy()\n",
    "\n",
    "print(\"Recommended Medication IDs:\", recommended_meds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ft41WW5HbsZ"
   },
   "source": [
    "## Get Medications' names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743598613201,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "zVat23w9kgWK"
   },
   "outputs": [],
   "source": [
    "data_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1743598613349,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "h2xCzAoFj0hz"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(data_path, \"mappings\", \"id_to_medication.json\"), 'r') as file:\n",
    "    med_map = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743598613508,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "_cAdya7_k4GN",
    "outputId": "cdbf95f8-d804-4f0e-eb73-cc9ed45b620e"
   },
   "outputs": [],
   "source": [
    "print(f\"Top {topk} Recommended medications for patient {patient_id}:\\n\")\n",
    "for med_id in recommended_meds:\n",
    "    print(\"-\", med_map[str(med_id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ymr_IHYMHYG3"
   },
   "source": [
    "## Patient's Condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743598616332,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "Aarr9-srGvWO"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(data_path, \"mappings\", \"id_to_disease.json\"), \"r\") as f:\n",
    "    disease_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1743598617142,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "P79RZYyeH-yi",
    "outputId": "66bd5295-2737-46ef-b4bf-0ed99f9d334b"
   },
   "outputs": [],
   "source": [
    "edge_index = data[\"patient\", \"has_disease\", \"disease\"].edge_index\n",
    "\n",
    "# Filter edges where patient is the source\n",
    "mask = edge_index[0] == patient_id\n",
    "disease_ids = edge_index[1][mask].cpu().numpy()\n",
    "disease_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743598617876,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "lIRBAdLhJlmj",
    "outputId": "969df00e-59d5-427b-e414-3fcd48a4ae5e"
   },
   "outputs": [],
   "source": [
    "print(f\"Conditions of patient {patient_id}:\\n\")\n",
    "for disease_id in disease_ids:\n",
    "    print(\"-\", disease_mapping[str(disease_id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4haLb-oaJRA"
   },
   "source": [
    "## Get Patient's Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1743598623894,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "BWFNas5bW7O0"
   },
   "outputs": [],
   "source": [
    "# Load saved encoder and scaler\n",
    "encoder = joblib.load(os.path.join(data_path,\"models\", \"patient_gender_ethnicity_encoder.pkl\"))\n",
    "age_scaler = joblib.load(os.path.join(data_path,\"models\" ,\"patient_age_scaler.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743598624064,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "vgBnooa2W8bQ",
    "outputId": "19b8d9ed-0706-498d-be85-28b9121179d0"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming feature layout: [scaled_age, onehot_gender, onehot_ethnicity]\n",
    "patient_vector = data[\"patient\"].x[patient_id].cpu().numpy()\n",
    "\n",
    "scaled_age = patient_vector[0:1]\n",
    "encoded_demo = patient_vector[1:]\n",
    "\n",
    "# Recover original age\n",
    "original_age = age_scaler.inverse_transform(scaled_age.reshape(1, -1))[0][0]\n",
    "\n",
    "# Recover gender and ethnicity\n",
    "original_demo = encoder.inverse_transform(encoded_demo.reshape(1, -1))[0]\n",
    "original_gender, original_ethnicity = original_demo\n",
    "\n",
    "print(\"Recovered Info:\")\n",
    "print(\"Age:\", original_age)\n",
    "print(\"Gender:\", original_gender)\n",
    "print(\"Ethnicity:\", original_ethnicity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuvwuVH1trHD"
   },
   "source": [
    "## Patient's Procedures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1743598625392,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "pxAIlqdcuA8T"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, \"mappings\", \"id_to_procedure.json\"), \"r\") as f:\n",
    "    procedure_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1743598625689,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "n1DoP9_Ntqzd",
    "outputId": "ec1fd12f-ea79-4312-c1fe-3bf137381aa4"
   },
   "outputs": [],
   "source": [
    "# Step 1: Get edge index for \"underwent\" relation\n",
    "edge_index_proc = data[\"patient\", \"underwent\", \"procedure\"].edge_index\n",
    "\n",
    "# Step 2: Filter where patient is the source node\n",
    "mask_proc = edge_index_proc[0] == patient_id\n",
    "\n",
    "# Step 3: Get corresponding procedure IDs (target nodes)\n",
    "procedure_ids = edge_index_proc[1][mask_proc].cpu().numpy()\n",
    "procedure_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1743598626590,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "8uOeEgv5uKcd",
    "outputId": "86b49f14-6d12-4efa-98b2-de21202fde93"
   },
   "outputs": [],
   "source": [
    "print(f\"Procedures of patient {patient_id}:\\n\")\n",
    "for pid in procedure_ids:\n",
    "    print(\"-\", procedure_mapping[str(pid)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUS8dINbaSIy"
   },
   "source": [
    "## Get Patient's Lab IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1743598627696,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "Ti2i6pLzaVJZ",
    "outputId": "04f904f9-697d-4b5f-db74-6b64bb23af2e"
   },
   "outputs": [],
   "source": [
    "# Step 1: Get edge index for patient-lab relation\n",
    "edge_index_lab = data[\"patient\", \"has_lab\", \"lab\"].edge_index\n",
    "\n",
    "# Step 2: Filter for edges where the patient is the source\n",
    "mask_lab = edge_index_lab[0] == patient_id\n",
    "\n",
    "# Step 3: Extract corresponding lab node IDs\n",
    "lab_ids = edge_index_lab[1][mask_lab].cpu().numpy()\n",
    "lab_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ByZWCw6L9l_"
   },
   "source": [
    "## New Patient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWWoz5uXOx4X"
   },
   "source": [
    "### Add Disease Node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1743598705877,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "6icAMSF4Jn1t",
    "outputId": "5de68a22-5281-4644-b8d2-3da4bfffa5bb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load saved encoder and scaler\n",
    "encoder = joblib.load(os.path.join(data_path,\"models\", \"patient_gender_ethnicity_encoder.pkl\"))\n",
    "age_scaler = joblib.load(os.path.join(data_path, \"models\",\"patient_age_scaler.pkl\"))\n",
    "\n",
    "# New patient info (Input)\n",
    "gender = 0\n",
    "ethnicity = 1\n",
    "age = 67\n",
    "\n",
    "# Wrap in DataFrames to preserve feature names\n",
    "new_patient_demo = pd.DataFrame([[gender, ethnicity]], columns=[\"gender\", \"ethnicity\"])\n",
    "new_patient_age = pd.DataFrame([[age]], columns=[\"age\"])\n",
    "\n",
    "# Transform using fitted encoders\n",
    "encoded_demo = encoder.transform(new_patient_demo)\n",
    "scaled_age = age_scaler.transform(new_patient_age)\n",
    "\n",
    "# Concatenate into feature vector\n",
    "new_patient_features = np.hstack([scaled_age, encoded_demo])\n",
    "new_patient_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1743598706207,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "sJ3lENSYpkbI"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import ToUndirected\n",
    "\n",
    "# Context mapping builders\n",
    "def build_first_association_map(patient_nodes, context_nodes):\n",
    "    # patient_nodes and context_nodes are tensors\n",
    "    mapping = {}\n",
    "    for p, c in zip(patient_nodes.tolist(), context_nodes.tolist()):\n",
    "        if p not in mapping:\n",
    "            mapping[p] = c\n",
    "    return mapping\n",
    "\n",
    "# Lookup functions for context\n",
    "def get_first_associated_node(context_map, patient_ids):\n",
    "    return torch.tensor([context_map.get(pid.item(), 0) for pid in patient_ids], dtype=torch.long).to(patient_ids.device)\n",
    "\n",
    "\n",
    "def predict_with_node_addition(\n",
    "    model,\n",
    "    data,\n",
    "    new_patient_features,     # shape: [1, input_dim]\n",
    "    disease_ids,              # list or tensor of disease node indices\n",
    "    procedure_ids,            # list or tensor of procedure node indices\n",
    "    lab_ids,                  # list or tensor of lab node indices\n",
    "    disease_map_fn,           # function to build disease_map\n",
    "    procedure_map_fn,         # function to build procedure_map\n",
    "    lab_map_fn,               # function to build lab_map\n",
    "    med_map,                  # medication ID to name mapping\n",
    "    device,\n",
    "    topk=10\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Step 1: Clone the original graph to avoid mutation\n",
    "        inference_data = data.clone()\n",
    "\n",
    "        # Step 2: Assign new patient ID\n",
    "        new_patient_tensor = torch.tensor(new_patient_features, dtype=torch.float).to(device)\n",
    "        new_patient_id = inference_data[\"patient\"].x.shape[0]\n",
    "\n",
    "        # Step 3: Add patient node\n",
    "        inference_data[\"patient\"].x = torch.cat(\n",
    "            [inference_data[\"patient\"].x, new_patient_tensor], dim=0\n",
    "        )\n",
    "\n",
    "        # Step 4: Add edges\n",
    "        def add_edges(edge_type, target_ids):\n",
    "            edge_index = torch.stack([\n",
    "                torch.full((len(target_ids),), new_patient_id, dtype=torch.long),  # source\n",
    "                torch.tensor(target_ids, dtype=torch.long)\n",
    "            ], dim=0).to(device)\n",
    "            inference_data[edge_type].edge_index = torch.cat([\n",
    "                inference_data[edge_type].edge_index.to(device),\n",
    "                edge_index\n",
    "            ], dim=1)\n",
    "\n",
    "        add_edges((\"patient\", \"has_disease\", \"disease\"), disease_ids)\n",
    "        add_edges((\"patient\", \"underwent\", \"procedure\"), procedure_ids)\n",
    "        add_edges((\"patient\", \"has_lab\", \"lab\"), lab_ids)\n",
    "\n",
    "        # Step 5: Reapply ToUndirected to get reverse edges\n",
    "        inference_data = ToUndirected()(inference_data)\n",
    "\n",
    "        # Step 6: Rebuild context maps\n",
    "        disease_map = disease_map_fn(\n",
    "            inference_data[\"patient\", \"has_disease\", \"disease\"].edge_index[0],\n",
    "            inference_data[\"patient\", \"has_disease\", \"disease\"].edge_index[1]\n",
    "        )\n",
    "        procedure_map = procedure_map_fn(\n",
    "            inference_data[\"patient\", \"underwent\", \"procedure\"].edge_index[0],\n",
    "            inference_data[\"patient\", \"underwent\", \"procedure\"].edge_index[1]\n",
    "        )\n",
    "        lab_map = lab_map_fn(\n",
    "            inference_data[\"patient\", \"has_lab\", \"lab\"].edge_index[0],\n",
    "            inference_data[\"patient\", \"has_lab\", \"lab\"].edge_index[1]\n",
    "        )\n",
    "\n",
    "        # Step 7: Forward pass\n",
    "        z_dict = model(inference_data.x_dict, inference_data.edge_index_dict)\n",
    "\n",
    "        # Replace patient embeddings using the patient_encoder MLP\n",
    "        patient_features = inference_data[\"patient\"].x.to(device)\n",
    "        z_dict[\"patient\"] = model.encode_patient(patient_features)  # <-- Encoder used here\n",
    "\n",
    "        num_meds = z_dict[\"medication\"].shape[0]\n",
    "        med_ids = torch.arange(num_meds).to(device)\n",
    "        patients = torch.full((num_meds,), new_patient_id, dtype=torch.long).to(device)\n",
    "\n",
    "        edge_index = torch.stack([patients, med_ids], dim=0)\n",
    "\n",
    "        disease_ids_batch   = get_first_associated_node(disease_map, patients)\n",
    "        procedure_ids_batch = get_first_associated_node(procedure_map, patients)\n",
    "        lab_ids_batch       = get_first_associated_node(lab_map, patients)\n",
    "\n",
    "        # Step 8: Decode predictions\n",
    "        scores = model.decode(\n",
    "            z_patient     = z_dict[\"patient\"],\n",
    "            z_medication  = z_dict[\"medication\"],\n",
    "            z_disease     = z_dict[\"disease\"],\n",
    "            z_procedure   = z_dict[\"procedure\"],\n",
    "            z_lab         = z_dict[\"lab\"],\n",
    "            edge_index    = edge_index,\n",
    "            disease_ids   = disease_ids_batch,\n",
    "            procedure_ids = procedure_ids_batch,\n",
    "            lab_ids       = lab_ids_batch\n",
    "        )\n",
    "\n",
    "        probs = torch.sigmoid(scores)\n",
    "\n",
    "        # Step 9: Top-k results\n",
    "        top_indices = probs.topk(topk).indices\n",
    "        recommended_med_ids = med_ids[top_indices].cpu().numpy()\n",
    "        top_scores = probs[top_indices].cpu().numpy()\n",
    "\n",
    "        print(f\"\\nTop {topk} Recommended Medications for Patient {new_patient_id}:\\n\")\n",
    "        for med_id, score in zip(recommended_med_ids, top_scores):\n",
    "            print(f\"- {med_map[str(med_id)]}: {score:.4f}\")\n",
    "\n",
    "        return recommended_med_ids, top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34094,
     "status": "ok",
     "timestamp": 1743598741232,
     "user": {
      "displayName": "Lu Kyaw",
      "userId": "00606119636179503189"
     },
     "user_tz": -420
    },
    "id": "vdwHMvwCp16C",
    "outputId": "52f8da79-e4c6-4bbc-bb82-a250bdc1bc6b"
   },
   "outputs": [],
   "source": [
    "recommendations, scores = predict_with_node_addition(\n",
    "    model=model,\n",
    "    data=data,\n",
    "    new_patient_features=new_patient_features,\n",
    "    disease_ids=disease_ids,\n",
    "    procedure_ids=procedure_ids,\n",
    "    lab_ids=lab_ids,\n",
    "    disease_map_fn=build_first_association_map,\n",
    "    procedure_map_fn=build_first_association_map,\n",
    "    lab_map_fn=build_first_association_map,\n",
    "    med_map=med_map,  # {\"0\": \"Drug A\", ...}\n",
    "    device=device,\n",
    "    topk=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhpis46q_VaD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOxIhAxf8qqyHLIXMrmzWq1",
   "machine_shape": "hm",
   "mount_file_id": "1_jZbXKZKNV2gSbwlt5rjVx41CUIzMgyK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
